{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10494067",
   "metadata": {},
   "source": [
    "## M1 monetary aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69da4be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\M1_EU_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\M1_USA_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\M1_PEN_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\M1_ZAR_daily.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# M1 monthly -> daily (log-linear interpolation)\n",
    "# ---------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "base_dir = Path(r\"C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\")\n",
    "data_dir = base_dir / \"1. data\"\n",
    "out_dir  = base_dir / \"2. preprocesing\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Window\n",
    "RAW_START   = \"2014-12-31\"\n",
    "FINAL_START = \"2015-01-01\"\n",
    "END_DATE    = \"2024-12-31\"\n",
    "\n",
    "def _clean_numeric(s):\n",
    "    \"\"\"Coerce strings like '1,239,868,918,894.70' -> float.\"\"\"\n",
    "    if pd.isna(s): return np.nan\n",
    "    if isinstance(s, (int, float)): return float(s)\n",
    "    s = str(s).replace(',', '').strip()\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "def monthly_stock_to_daily_loginterp(df_m, date_col, value_col):\n",
    "    \"\"\"Core: log-linear interpolate monthly stock to daily.\"\"\"\n",
    "    m = df_m[[date_col, value_col]].copy()\n",
    "    m.columns = [\"date\", \"m1\"]\n",
    "    m[\"date\"] = pd.to_datetime(m[\"date\"], errors=\"coerce\")\n",
    "    m[\"m1\"]   = m[\"m1\"].map(_clean_numeric)\n",
    "    m = m[(m[\"date\"] >= RAW_START) & (m[\"date\"] <= END_DATE)].dropna().sort_values(\"date\")\n",
    "    m = m.set_index(\"date\")\n",
    "\n",
    "    # logs -> linear interp in log space\n",
    "    m[\"log_m1\"] = np.log(m[\"m1\"])\n",
    "    daily_index = pd.date_range(start=RAW_START, end=END_DATE, freq=\"D\")\n",
    "    d = m[[\"log_m1\"]].reindex(daily_index).interpolate(method=\"linear\")\n",
    "    d = d.loc[FINAL_START:].copy()\n",
    "    d[\"m1_daily\"] = np.exp(d[\"log_m1\"])\n",
    "\n",
    "    # optional normalized index 2015-01=100 (solo para gráficos)\n",
    "    base_val = d.loc[pd.Timestamp(\"2015-01-01\"), \"m1_daily\"]\n",
    "    d[\"m1_rebased_2015m1_100\"] = (d[\"m1_daily\"] / base_val) * 100.0\n",
    "\n",
    "    d.index.name = \"date\"\n",
    "    return d.reset_index().rename(columns={\"log_m1\": \"log_m1_daily\"})\n",
    "\n",
    "# -----------------------------\n",
    "# EURO AREA (ECB file)\n",
    "# cols: \"DATE\",\"TIME PERIOD\",\"Monetary aggregate M1 ... \"\n",
    "# value = 3ra columna\n",
    "# -----------------------------\n",
    "m1_eu = pd.read_csv(data_dir / \"M1_EU.csv\")\n",
    "m1_eu.columns = m1_eu.columns.str.strip()\n",
    "eu_date_col   = \"DATE\"\n",
    "eu_value_col  = m1_eu.columns[-1]  # última columna numérica\n",
    "eu_daily = monthly_stock_to_daily_loginterp(m1_eu, eu_date_col, eu_value_col)\n",
    "eu_daily.to_csv(out_dir / \"M1_EU_daily.csv\", index=False)\n",
    "print(\"Saved:\", out_dir / \"M1_EU_daily.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# USA (ajusta nombres según tu CSV)\n",
    "# si tu archivo tiene 2 primeras columnas [DATE, M1], usa eso;\n",
    "# en caso de duda, toma segunda columna como valor.\n",
    "# -----------------------------\n",
    "m1_us = pd.read_csv(data_dir / \"M1_USA.csv\")\n",
    "m1_us.columns = m1_us.columns.str.strip()\n",
    "us_date_col  = m1_us.columns[0]\n",
    "us_value_col = m1_us.columns[1]  # ajusta si tu header es 'M1'/'M1SL'\n",
    "us_daily = monthly_stock_to_daily_loginterp(m1_us, us_date_col, us_value_col)\n",
    "us_daily.to_csv(out_dir / \"M1_USA_daily.csv\", index=False)\n",
    "print(\"Saved:\", out_dir / \"M1_USA_daily.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# PERU (semicolon, d/m/Y)\n",
    "# -----------------------------\n",
    "m1_pe = pd.read_csv(data_dir / \"M1_PEN.csv\", sep=';')\n",
    "m1_pe.columns = m1_pe.columns.str.strip()\n",
    "pe_date_col  = \"date\"\n",
    "pe_value_col = [c for c in m1_pe.columns if c.lower().startswith(\"m1\")][0]  # 'M1_PEN'\n",
    "# Normaliza fecha d/m/Y -> ISO\n",
    "m1_pe[\"date\"] = pd.to_datetime(m1_pe[\"date\"], dayfirst=True, errors=\"coerce\")\n",
    "pe_daily = monthly_stock_to_daily_loginterp(m1_pe, pe_date_col, pe_value_col)\n",
    "pe_daily.to_csv(out_dir / \"M1_PEN_daily.csv\", index=False)\n",
    "print(\"Saved:\", out_dir / \"M1_PEN_daily.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# SOUTH AFRICA (semicolon; extra cols ZAR, DEX..., USD)\n",
    "# usaremos la columna 'ZAR' (en moneda local), ignorar USD y tipo de cambio.\n",
    "# -----------------------------\n",
    "m1_za = pd.read_csv(data_dir / \"M1_ZAR.csv\", sep=';')\n",
    "m1_za.columns = m1_za.columns.str.replace('\\ufeff','', regex=False).str.strip()\n",
    "# Algunos CSV vienen con nombres como 'ZAR ' con espacios; limpiamos:\n",
    "rename_map = {c: c.strip() for c in m1_za.columns}\n",
    "m1_za = m1_za.rename(columns=rename_map)\n",
    "za_date_col  = \"date\"\n",
    "za_value_col = \"ZAR\"\n",
    "za_daily = monthly_stock_to_daily_loginterp(m1_za, za_date_col, za_value_col)\n",
    "za_daily.to_csv(out_dir / \"M1_ZAR_daily.csv\", index=False)\n",
    "print(\"Saved:\", out_dir / \"M1_ZAR_daily.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84cba4",
   "metadata": {},
   "source": [
    "## Interest rate - 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0dea195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\interest_rate_3m_EU_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\interest_rate_3m_USA_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\interest_rate_3m_PEN_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\interest_rate_3m_ZAR_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rate_percent</th>\n",
       "      <th>rate_decimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>6.007619</td>\n",
       "      <td>0.060076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>6.007619</td>\n",
       "      <td>0.060076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>6.007619</td>\n",
       "      <td>0.060076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>6.007619</td>\n",
       "      <td>0.060076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>6.007619</td>\n",
       "      <td>0.060076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  rate_percent  rate_decimal\n",
       "0    2015-01-01      6.007619      0.060076\n",
       "1    2015-01-02      6.007619      0.060076\n",
       "2    2015-01-03      6.007619      0.060076\n",
       "3    2015-01-04      6.007619      0.060076\n",
       "4    2015-01-05      6.007619      0.060076\n",
       "...         ...           ...           ...\n",
       "3648 2024-12-27      7.800000      0.078000\n",
       "3649 2024-12-28      7.800000      0.078000\n",
       "3650 2024-12-29      7.800000      0.078000\n",
       "3651 2024-12-30      7.800000      0.078000\n",
       "3652 2024-12-31      7.800000      0.078000\n",
       "\n",
       "[3653 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 3M Interest Rate (monthly) -> Daily (step/ffill)\n",
    "# ---------------------------------------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "base_dir = Path(r\"C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\")\n",
    "data_dir = base_dir / \"1. data\"\n",
    "out_dir  = base_dir / \"2. preprocesing\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Date window\n",
    "RAW_START   = \"2014-12-31\"   # buffer day\n",
    "FINAL_START = \"2015-01-01\"\n",
    "END_DATE    = \"2024-12-31\"\n",
    "\n",
    "def _coerce_find_column(cols, target):\n",
    "    \"\"\"Find `target` in `cols` tolerating BOM/spaces/case diffs.\"\"\"\n",
    "    norm = lambda s: s.replace('\\ufeff','').strip().lower().replace(' ', '')\n",
    "    t = norm(target)\n",
    "    # exact\n",
    "    for c in cols:\n",
    "        if c == target:\n",
    "            return c\n",
    "    # tolerant\n",
    "    cands = [c for c in cols if norm(c) == t]\n",
    "    if len(cands) == 1:\n",
    "        return cands[0]\n",
    "    raise KeyError(f\"Column '{target}' not found. Available: {list(cols)}\")\n",
    "\n",
    "def monthly_rate_to_daily_ffill(\n",
    "    filepath: Path,\n",
    "    date_col: str,\n",
    "    rate_col: str,\n",
    "    out_name: str,\n",
    "    source_unit: str = \"percent\"  # 'percent' (e.g., 0.03 or 6.15) or 'decimal' (0.0003 or 0.0615)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a MONTHLY 3M interest rate series to DAILY by forward-fill within month.\n",
    "    Saves both percent and decimal columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    # Clean headers\n",
    "    df.columns = df.columns.str.replace('\\ufeff','', regex=False).str.strip()\n",
    "\n",
    "    # Resolve column names robustly\n",
    "    date_col = _coerce_find_column(df.columns, date_col)\n",
    "    rate_col = _coerce_find_column(df.columns, rate_col)\n",
    "\n",
    "    # Keep & rename\n",
    "    m = df[[date_col, rate_col]].rename(columns={date_col: \"date\", rate_col: \"rate_raw\"}).copy()\n",
    "    m[\"date\"] = pd.to_datetime(m[\"date\"], errors=\"coerce\")\n",
    "    m = m[(m[\"date\"] >= RAW_START) & (m[\"date\"] <= END_DATE)].sort_values(\"date\")\n",
    "    m[\"rate_raw\"] = pd.to_numeric(m[\"rate_raw\"], errors=\"coerce\")\n",
    "\n",
    "    # Units -> percent & decimal\n",
    "    if source_unit.lower() == \"percent\":\n",
    "        # Examples: EU ~0.06 (0.06%), USA TB3MS ~0.03 (%), ZAR ~6.0 (%), PEN ~2.9 (%)\n",
    "        m[\"rate_percent\"] = m[\"rate_raw\"]\n",
    "        m[\"rate_decimal\"] = m[\"rate_raw\"] / 100.0\n",
    "    elif source_unit.lower() == \"decimal\":\n",
    "        m[\"rate_decimal\"] = m[\"rate_raw\"]\n",
    "        m[\"rate_percent\"] = m[\"rate_raw\"] * 100.0\n",
    "    else:\n",
    "        raise ValueError(\"source_unit must be 'percent' or 'decimal'.\")\n",
    "\n",
    "    # Map to daily with forward-fill (step per month)\n",
    "    daily_index = pd.date_range(start=RAW_START, end=END_DATE, freq=\"D\")\n",
    "    d = m.set_index(\"date\")[[\"rate_percent\", \"rate_decimal\"]].reindex(daily_index).ffill()\n",
    "    d = d.loc[FINAL_START:].copy()\n",
    "    d.index.name = \"date\"\n",
    "    d = d.reset_index()\n",
    "\n",
    "    # Save\n",
    "    out_path = out_dir / out_name\n",
    "    d.to_csv(out_path, index=False)\n",
    "    print(f\"Saved: {out_path}\")\n",
    "    return d\n",
    "\n",
    "# -----------------------------\n",
    "# Euro Area (OECD IR3TIB01EZM156N) -> in percent\n",
    "# -----------------------------\n",
    "monthly_rate_to_daily_ffill(\n",
    "    filepath  = data_dir / \"interest_rate_3m_EU.csv\",\n",
    "    date_col  = \"observation_date\",\n",
    "    rate_col  = \"IR3TIB01EZM156N\",\n",
    "    out_name  = \"interest_rate_3m_EU_daily.csv\",\n",
    "    source_unit = \"percent\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# USA (FRED TB3MS) -> in percent\n",
    "# -----------------------------\n",
    "monthly_rate_to_daily_ffill(\n",
    "    filepath  = data_dir / \"interest_rate_3m_USA.csv\",\n",
    "    date_col  = \"observation_date\",\n",
    "    rate_col  = \"TB3MS\",\n",
    "    out_name  = \"interest_rate_3m_USA_daily.csv\",\n",
    "    source_unit = \"percent\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Peru (BCRP monthly average) -> in percent\n",
    "# Note: missing 2015-03; daily ffill will bridge that gap cleanly.\n",
    "# -----------------------------\n",
    "monthly_rate_to_daily_ffill(\n",
    "    filepath  = data_dir / \"interest_rate_3m_PEN.csv\",\n",
    "    date_col  = \"date\",\n",
    "    rate_col  = \"1_dia-3_meses_average\",\n",
    "    out_name  = \"interest_rate_3m_PEN_daily.csv\",\n",
    "    source_unit = \"percent\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# South Africa (OECD IR3TIB01ZAM156N) -> in percent\n",
    "# -----------------------------\n",
    "monthly_rate_to_daily_ffill(\n",
    "    filepath  = data_dir / \"interest_rate_3m_ZAR.csv\",\n",
    "    date_col  = \"observation_date\",\n",
    "    rate_col  = \"IR3TIB01ZAM156N\",\n",
    "    out_name  = \"interest_rate_3m_ZAR_daily.csv\",\n",
    "    source_unit = \"percent\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa821a4",
   "metadata": {},
   "source": [
    "## Industrial production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98d1f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\INDPRO_EU_daily_SA.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\INDPRO_USA_daily_SA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luish\\AppData\\Local\\Temp\\ipykernel_38896\\3645918543.py:71: UserWarning: X-13 unavailable or failed (x12a and x13as not found on path. Give the path, put them on PATH, or set the X12PATH or X13PATH environmental variable.). Falling back to STL multiplicative.\n",
      "  warnings.warn(f\"X-13 unavailable or failed ({e}). Falling back to STL multiplicative.\")\n",
      "C:\\Users\\luish\\AppData\\Local\\Temp\\ipykernel_38896\\3645918543.py:71: UserWarning: X-13 unavailable or failed (x12a and x13as not found on path. Give the path, put them on PATH, or set the X12PATH or X13PATH environmental variable.). Falling back to STL multiplicative.\n",
      "  warnings.warn(f\"X-13 unavailable or failed ({e}). Falling back to STL multiplicative.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\INDPRO_ZAR_daily_SA.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\INDPRO_PEN_daily_SA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luish\\AppData\\Local\\Temp\\ipykernel_38896\\3645918543.py:71: UserWarning: X-13 unavailable or failed (x12a and x13as not found on path. Give the path, put them on PATH, or set the X12PATH or X13PATH environmental variable.). Falling back to STL multiplicative.\n",
      "  warnings.warn(f\"X-13 unavailable or failed ({e}). Falling back to STL multiplicative.\")\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Industrial Production -> Seasonally Adjusted -> Daily (log-linear)\n",
    "# ------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Paths\n",
    "base_dir = Path(r\"C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\")\n",
    "data_dir = base_dir / \"1. data\"\n",
    "out_dir  = base_dir / \"2. preprocesing\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Date window\n",
    "RAW_START   = \"2014-12-31\"\n",
    "FINAL_START = \"2015-01-01\"\n",
    "END_DATE    = \"2024-12-31\"\n",
    "\n",
    "# ------------- helpers -------------\n",
    "def _clean_numeric(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)): return float(x)\n",
    "    s = str(x).replace(',', '').strip()\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def _ensure_monthly_contiguous(df, date_col, value_col):\n",
    "    \"\"\"\n",
    "    Ensure a contiguous monthly (MS) index between FINAL_START..END_DATE.\n",
    "    Linear interpolation for rare gaps BEFORE seasonal adjustment.\n",
    "    \"\"\"\n",
    "    m = df[[date_col, value_col]].copy()\n",
    "    m.columns = [\"date\", \"val\"]\n",
    "    m[\"date\"] = pd.to_datetime(m[\"date\"], errors=\"coerce\")\n",
    "    m[\"val\"]  = m[\"val\"].map(_clean_numeric)\n",
    "    m = m[(m[\"date\"] >= FINAL_START) & (m[\"date\"] <= END_DATE)].dropna(subset=[\"date\"])\n",
    "\n",
    "    # Snap to month start (use how='S' instead of 'MS' arg)\n",
    "    m[\"date\"] = m[\"date\"].dt.to_period(\"M\").dt.to_timestamp(how=\"S\")\n",
    "    m = m.groupby(\"date\", as_index=True)[\"val\"].last().to_frame()\n",
    "\n",
    "    # Reindex to full monthly span\n",
    "    monthly_index = pd.date_range(start=FINAL_START, end=END_DATE, freq=\"MS\")\n",
    "    m = m.reindex(monthly_index)\n",
    "\n",
    "    # Fill odd missing month via linear interpolation (before SA)\n",
    "    m[\"val\"] = m[\"val\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "    m.index.name = \"date\"\n",
    "    return m\n",
    "\n",
    "def seasonally_adjust_monthly(df, date_col, value_col, already_sa=False):\n",
    "    \"\"\"\n",
    "    Return a DataFrame with columns ['date','ip_sa'] (monthly, MS).\n",
    "    If already_sa=True, only cleans and standardizes.\n",
    "    Else: try X-13; fallback to STL multiplicative on logs.\n",
    "    \"\"\"\n",
    "    m = _ensure_monthly_contiguous(df, date_col, value_col)\n",
    "\n",
    "    if already_sa:\n",
    "        out = m.rename(columns={\"val\": \"ip_sa\"}).reset_index()\n",
    "        return out\n",
    "\n",
    "    # Try X-13 (if installed); fallback STL multiplicative\n",
    "    ip_sa = None\n",
    "    try:\n",
    "        from statsmodels.tsa.x13 import x13_arima_analysis as x13\n",
    "        tmp = m[\"val\"].dropna()\n",
    "        res = x13(tmp, freq='M')\n",
    "        ip_sa = res.seasadj.reindex(m.index)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"X-13 unavailable or failed ({e}). Falling back to STL multiplicative.\")\n",
    "        from statsmodels.tsa.seasonal import STL\n",
    "        y = np.log(m[\"val\"])\n",
    "        stl = STL(y, period=12, robust=True)\n",
    "        fit = stl.fit()\n",
    "        # multiplicative SA = exp(trend + resid)\n",
    "        sa_log = fit.trend + fit.resid\n",
    "        ip_sa = np.exp(sa_log)\n",
    "\n",
    "    out = pd.DataFrame({\"date\": m.index, \"ip_sa\": ip_sa.values})\n",
    "    return out\n",
    "\n",
    "def sa_monthly_to_daily_loginterp(df_sa, value_col=\"ip_sa\"):\n",
    "    \"\"\"\n",
    "    Monthly SA index -> DAILY via log-linear.\n",
    "    Returns: ['date','ip_daily_sa','log_ip_daily_sa','ip_rebased_2015m1_100','log_ip_rebased_2015m1_100'].\n",
    "    \"\"\"\n",
    "    m = df_sa.copy()\n",
    "    m = m[(m[\"date\"] >= FINAL_START) & (m[\"date\"] <= END_DATE)].dropna(subset=[value_col])\n",
    "    m = m.set_index(\"date\").sort_index()\n",
    "\n",
    "    m[\"log_ip\"] = np.log(m[value_col])\n",
    "    daily_index = pd.date_range(start=RAW_START, end=END_DATE, freq=\"D\")\n",
    "    d = m[[\"log_ip\"]].reindex(daily_index).interpolate(method=\"linear\")\n",
    "    d = d.loc[FINAL_START:].copy()\n",
    "    d[\"ip_daily_sa\"] = np.exp(d[\"log_ip\"])\n",
    "    d.index.name = \"date\"\n",
    "\n",
    "    # Rebase (fallback to first available in Jan-2015 if exact day missing)\n",
    "    base_date = pd.Timestamp(\"2015-01-01\")\n",
    "    if base_date in d.index:\n",
    "        base_val = d.loc[base_date, \"ip_daily_sa\"]\n",
    "    else:\n",
    "        jan2015 = d.loc[\"2015-01-01\":\"2015-01-31\"]\n",
    "        base_val = jan2015[\"ip_daily_sa\"].iloc[0]\n",
    "    d[\"ip_rebased_2015m1_100\"] = (d[\"ip_daily_sa\"] / base_val) * 100.0\n",
    "    d[\"log_ip_rebased_2015m1_100\"] = np.log(d[\"ip_rebased_2015m1_100\"])\n",
    "\n",
    "    return d.reset_index().rename(columns={\"log_ip\": \"log_ip_daily_sa\"})\n",
    "\n",
    "# ------------- EURO AREA (already SA) -------------\n",
    "eu = pd.read_csv(data_dir / \"INDPRO_EU.csv\")\n",
    "eu.columns = eu.columns.str.replace('\\ufeff','', regex=False).str.strip()\n",
    "eu_sa_m = seasonally_adjust_monthly(eu, date_col=\"date\", value_col=\"ind_pro_sa_index_2021\", already_sa=True)\n",
    "eu_sa_d = sa_monthly_to_daily_loginterp(eu_sa_m, value_col=\"ip_sa\")\n",
    "eu_sa_d.to_csv(out_dir / \"INDPRO_EU_daily_SA.csv\", index=False)\n",
    "print(\"Saved:\", out_dir / \"INDPRO_EU_daily_SA.csv\")\n",
    "\n",
    "# ------------- USA (likely NSA: IPB50001N) -------------\n",
    "us = pd.read_csv(data_dir / \"INDPRO_USA.csv\")\n",
    "us.columns = us.columns.str.strip()\n",
    "us_sa_m = seasonally_adjust_monthly(us, date_col=\"observation_date\", value_col=\"IPB50001N\", already_sa=False)\n",
    "us_sa_d = sa_monthly_to_daily_loginterp(us_sa_m, value_col=\"ip_sa\")\n",
    "us_sa_d.to_csv(out_dir / \"INDPRO_USA_daily_SA.csv\", index=False)\n",
    "print(\"Saved:\", out_dir / \"INDPRO_USA_daily_SA.csv\")\n",
    "\n",
    "# ------------- SOUTH AFRICA (NSA; semicolon + dayfirst) -------------\n",
    "za = pd.read_csv(data_dir / \"INDPRO_ZAR.csv\", sep=';')\n",
    "za.columns = za.columns.str.replace('\\ufeff','', regex=False).str.strip()\n",
    "za[\"observation_date\"] = pd.to_datetime(za[\"observation_date\"], dayfirst=True, errors=\"coerce\")\n",
    "za_sa_m = seasonally_adjust_monthly(za, date_col=\"observation_date\", value_col=\"index_2019_NSA\", already_sa=False)\n",
    "za_sa_d = sa_monthly_to_daily_loginterp(za_sa_m, value_col=\"ip_sa\")\n",
    "za_sa_d.to_csv(out_dir / \"INDPRO_ZAR_daily_SA.csv\", index=False)\n",
    "print(\"Saved:\", out_dir / \"INDPRO_ZAR_daily_SA.csv\")\n",
    "\n",
    "# ------------- PERU (NSA; manufactura index) -------------\n",
    "pe = pd.read_csv(data_dir / \"INDPRO_PEN.csv\")\n",
    "pe.columns = pe.columns.str.replace('\\ufeff','', regex=False).str.strip()\n",
    "pe_sa_m = seasonally_adjust_monthly(pe, date_col=\"date\", value_col=\"prod_manufacturera_index_2007_PN02079AM\", already_sa=False)\n",
    "pe_sa_d = sa_monthly_to_daily_loginterp(pe_sa_m, value_col=\"ip_sa\")\n",
    "pe_sa_d.to_csv(out_dir / \"INDPRO_PEN_daily_SA.csv\", index=False)\n",
    "print(\"Saved:\", out_dir / \"INDPRO_PEN_daily_SA.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4bd64c",
   "metadata": {},
   "source": [
    "## CPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72931dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\CPI_USA_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\CPI_EU_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\CPI_PEN_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\CPI_ZAR_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>log_cpi_daily</th>\n",
       "      <th>cpi_daily</th>\n",
       "      <th>cpi_rebased_2015m1_100</th>\n",
       "      <th>log_cpi_rebased_2015m1_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4.120662</td>\n",
       "      <td>61.600000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.605170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>4.120871</td>\n",
       "      <td>61.612863</td>\n",
       "      <td>100.020881</td>\n",
       "      <td>4.605379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>4.121079</td>\n",
       "      <td>61.625728</td>\n",
       "      <td>100.041767</td>\n",
       "      <td>4.605588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>4.121288</td>\n",
       "      <td>61.638597</td>\n",
       "      <td>100.062657</td>\n",
       "      <td>4.605797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>4.121497</td>\n",
       "      <td>61.651468</td>\n",
       "      <td>100.083551</td>\n",
       "      <td>4.606005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>162.337662</td>\n",
       "      <td>5.089679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>162.337662</td>\n",
       "      <td>5.089679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>162.337662</td>\n",
       "      <td>5.089679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>162.337662</td>\n",
       "      <td>5.089679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>162.337662</td>\n",
       "      <td>5.089679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  log_cpi_daily   cpi_daily  cpi_rebased_2015m1_100  \\\n",
       "0    2015-01-01       4.120662   61.600000              100.000000   \n",
       "1    2015-01-02       4.120871   61.612863              100.020881   \n",
       "2    2015-01-03       4.121079   61.625728              100.041767   \n",
       "3    2015-01-04       4.121288   61.638597              100.062657   \n",
       "4    2015-01-05       4.121497   61.651468              100.083551   \n",
       "...         ...            ...         ...                     ...   \n",
       "3648 2024-12-27       4.605170  100.000000              162.337662   \n",
       "3649 2024-12-28       4.605170  100.000000              162.337662   \n",
       "3650 2024-12-29       4.605170  100.000000              162.337662   \n",
       "3651 2024-12-30       4.605170  100.000000              162.337662   \n",
       "3652 2024-12-31       4.605170  100.000000              162.337662   \n",
       "\n",
       "      log_cpi_rebased_2015m1_100  \n",
       "0                       4.605170  \n",
       "1                       4.605379  \n",
       "2                       4.605588  \n",
       "3                       4.605797  \n",
       "4                       4.606005  \n",
       "...                          ...  \n",
       "3648                    5.089679  \n",
       "3649                    5.089679  \n",
       "3650                    5.089679  \n",
       "3651                    5.089679  \n",
       "3652                    5.089679  \n",
       "\n",
       "[3653 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# CPI monthly -> daily (log-linear interpolation)\n",
    "# ---------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Paths (edit if needed) ----\n",
    "base_dir = Path(r\"C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\")\n",
    "data_dir = base_dir / \"1. data\"\n",
    "out_dir  = base_dir / \"2. preprocesing\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Date window ----\n",
    "RAW_START   = \"2014-12-31\"   # buffer day for interpolation coverage\n",
    "FINAL_START = \"2015-01-01\"\n",
    "END_DATE    = \"2024-12-31\"\n",
    "\n",
    "def monthly_cpi_to_daily(\n",
    "    filepath: Path,\n",
    "    date_col: str,\n",
    "    value_col: str,\n",
    "    out_name: str,\n",
    "    rebase_2015m1: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load CPI monthly, produce DAILY CPI by log-linear interpolation.\n",
    "    Optionally rebase to 2015-01-01 = 100 for convenient comparability.\n",
    "    Output columns:\n",
    "      - date\n",
    "      - cpi_daily, log_cpi_daily\n",
    "      - (optional) cpi_rebased_2015m1_100, log_cpi_rebased_2015m1_100\n",
    "    \"\"\"\n",
    "    # Load & basic clean\n",
    "    m = pd.read_csv(filepath).rename(columns={date_col: \"date\", value_col: \"cpi\"})\n",
    "    m[\"date\"] = pd.to_datetime(m[\"date\"])\n",
    "    m = m[(m[\"date\"] >= RAW_START) & (m[\"date\"] <= END_DATE)].sort_values(\"date\")\n",
    "\n",
    "    # Interpolate in log space (→ constant daily growth between monthly fixes)\n",
    "    m = m.set_index(\"date\")\n",
    "    m[\"log_cpi\"] = np.log(m[\"cpi\"])\n",
    "\n",
    "    daily_index = pd.date_range(start=RAW_START, end=END_DATE, freq=\"D\")\n",
    "    d = m[[\"log_cpi\"]].reindex(daily_index).interpolate(method=\"linear\")\n",
    "    d = d.loc[FINAL_START:].copy()\n",
    "    d[\"cpi_daily\"] = np.exp(d[\"log_cpi\"])\n",
    "\n",
    "    # Optional rebase to 2015-01-01 = 100\n",
    "    if rebase_2015m1:\n",
    "        base_val = d.loc[pd.Timestamp(\"2015-01-01\"), \"cpi_daily\"]\n",
    "        d[\"cpi_rebased_2015m1_100\"] = (d[\"cpi_daily\"] / base_val) * 100.0\n",
    "        d[\"log_cpi_rebased_2015m1_100\"] = np.log(d[\"cpi_rebased_2015m1_100\"])\n",
    "\n",
    "    # Final tidy & save\n",
    "    d.index.name = \"date\"\n",
    "    d = d.reset_index().rename(columns={\"log_cpi\": \"log_cpi_daily\"})\n",
    "    d.to_csv(out_dir / out_name, index=False)\n",
    "    print(f\"Saved: {out_dir / out_name}\")\n",
    "    return d\n",
    "\n",
    "# -----------------------------\n",
    "# USA (FRED CPIAUCNS, monthly)\n",
    "# -----------------------------\n",
    "monthly_cpi_to_daily(\n",
    "    filepath = data_dir / \"CPI_AUCNS_USA.csv\",\n",
    "    date_col = \"observation_date\",\n",
    "    value_col = \"CPIAUCNS\",\n",
    "    out_name = \"CPI_USA_daily.csv\",\n",
    "    rebase_2015m1 = True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Euro Area HICP (CP0000EZ19M086NEST, monthly)\n",
    "# -----------------------------\n",
    "monthly_cpi_to_daily(\n",
    "    filepath = data_dir / \"CPI_HICP_EU.csv\",\n",
    "    date_col = \"observation_date\",\n",
    "    value_col = \"CP0000EZ19M086NEST\",\n",
    "    out_name = \"CPI_EU_daily.csv\",\n",
    "    rebase_2015m1 = True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Peru CPI (monthly; base Dec-2021=100 in your file)\n",
    "# -----------------------------\n",
    "monthly_cpi_to_daily(\n",
    "    filepath = data_dir / \"CPI_PEN.csv\",\n",
    "    date_col = \"date\",\n",
    "    value_col = \"CPI_index_dic_2021_PN38705PM\",\n",
    "    out_name = \"CPI_PEN_daily.csv\",\n",
    "    rebase_2015m1 = True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# South Africa CPI (clean monthly index as you clarified)\n",
    "# -----------------------------\n",
    "monthly_cpi_to_daily(\n",
    "    filepath = data_dir / \"CPI_ZAR.csv\",\n",
    "    date_col = \"date\",\n",
    "    value_col = \"cpi_index_dec_2024_value\",\n",
    "    out_name = \"CPI_ZAR_daily.csv\",\n",
    "    rebase_2015m1 = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ee59e",
   "metadata": {},
   "source": [
    "## Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736da6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\inflation_EU_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\inflation_PEN_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\inflation_USA_daily.csv\n",
      "Saved: C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\\2. preprocesing\\inflation_ZAR_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pi_yoy_percent</th>\n",
       "      <th>pi_yoy_decimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pi_yoy_percent  pi_yoy_decimal\n",
       "0    2015-01-01             4.4           0.044\n",
       "1    2015-01-02             4.4           0.044\n",
       "2    2015-01-03             4.4           0.044\n",
       "3    2015-01-04             4.4           0.044\n",
       "4    2015-01-05             4.4           0.044\n",
       "...         ...             ...             ...\n",
       "3648 2024-12-27             3.0           0.030\n",
       "3649 2024-12-28             3.0           0.030\n",
       "3650 2024-12-29             3.0           0.030\n",
       "3651 2024-12-30             3.0           0.030\n",
       "3652 2024-12-31             3.0           0.030\n",
       "\n",
       "[3653 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Inflation (YoY monthly) -> Daily (step/ffill)\n",
    "# ---------------------------------------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "base_dir = Path(r\"C:\\Users\\luish\\OneDrive - University of Leeds\\9. DISERTATION\\2. Development\\code\")\n",
    "data_dir = base_dir / \"1. data\"\n",
    "out_dir  = base_dir / \"2. preprocesing\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Date window\n",
    "RAW_START   = \"2014-12-31\"   # buffer day\n",
    "FINAL_START = \"2015-01-01\"\n",
    "END_DATE    = \"2024-12-31\"\n",
    "\n",
    "def _coerce_find_column(cols, target):\n",
    "    \"\"\"Find `target` in `cols` tolerating stray spaces/BOM/case differences.\"\"\"\n",
    "    norm = lambda s: s.replace('\\ufeff','').strip().lower().replace(' ', '')\n",
    "    target_n = norm(target)\n",
    "    # exact first\n",
    "    for c in cols:\n",
    "        if c == target:\n",
    "            return c\n",
    "    # tolerant\n",
    "    candidates = [c for c in cols if norm(c) == target_n]\n",
    "    if len(candidates) == 1:\n",
    "        return candidates[0]\n",
    "    raise KeyError(f\"Column '{target}' not found. Available: {list(cols)}\")\n",
    "\n",
    "def monthly_inflation_to_daily(\n",
    "    filepath: Path,\n",
    "    date_col: str,\n",
    "    rate_col: str,\n",
    "    out_name: str,\n",
    "    source_unit: str = \"percent\"   # \"percent\" or \"decimal\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert monthly YoY inflation to daily by forward-fill within month.\n",
    "    Outputs both percent and decimal:\n",
    "      - pi_yoy_percent\n",
    "      - pi_yoy_decimal\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    # Clean headers\n",
    "    df.columns = df.columns.str.replace('\\ufeff','', regex=False).str.strip()\n",
    "\n",
    "    # Resolve column names robustly\n",
    "    date_col  = _coerce_find_column(df.columns, date_col)\n",
    "    rate_col  = _coerce_find_column(df.columns, rate_col)\n",
    "\n",
    "    # Keep & rename\n",
    "    m = df[[date_col, rate_col]].rename(columns={date_col: \"date\", rate_col: \"pi_yoy_raw\"}).copy()\n",
    "    m[\"date\"] = pd.to_datetime(m[\"date\"], errors=\"coerce\")\n",
    "    m = m[(m[\"date\"] >= RAW_START) & (m[\"date\"] <= END_DATE)].sort_values(\"date\")\n",
    "    m[\"pi_yoy_raw\"] = pd.to_numeric(m[\"pi_yoy_raw\"], errors=\"coerce\")\n",
    "\n",
    "    # Units\n",
    "    if source_unit.lower() == \"percent\":\n",
    "        m[\"pi_yoy_percent\"] = m[\"pi_yoy_raw\"]\n",
    "        m[\"pi_yoy_decimal\"] = m[\"pi_yoy_raw\"] / 100.0\n",
    "    elif source_unit.lower() == \"decimal\":\n",
    "        m[\"pi_yoy_decimal\"] = m[\"pi_yoy_raw\"]\n",
    "        m[\"pi_yoy_percent\"] = m[\"pi_yoy_raw\"] * 100.0\n",
    "    else:\n",
    "        raise ValueError(\"source_unit must be 'percent' or 'decimal'.\")\n",
    "\n",
    "    # Map to daily with ffill (step function per month)\n",
    "    daily_index = pd.date_range(start=RAW_START, end=END_DATE, freq=\"D\")\n",
    "    d = m.set_index(\"date\")[[\"pi_yoy_percent\", \"pi_yoy_decimal\"]].reindex(daily_index).ffill()\n",
    "    d = d.loc[FINAL_START:].copy()\n",
    "    d.index.name = \"date\"\n",
    "    d = d.reset_index()\n",
    "\n",
    "    # Save\n",
    "    out_path = out_dir / out_name\n",
    "    d.to_csv(out_path, index=False)\n",
    "    print(f\"Saved: {out_path}\")\n",
    "    return d\n",
    "\n",
    "# -----------------------------\n",
    "# Euro Area (annual_change_rate_hicp) -> given in percent\n",
    "# -----------------------------\n",
    "monthly_inflation_to_daily(\n",
    "    filepath = data_dir / \"inflation_EU.csv\",\n",
    "    date_col = \"date\",\n",
    "    rate_col = \"annual_change_rate_hicp\",\n",
    "    out_name = \"inflation_EU_daily.csv\",\n",
    "    source_unit = \"percent\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Peru (var%_12_months_inflation_value) -> given in percent\n",
    "# -----------------------------\n",
    "monthly_inflation_to_daily(\n",
    "    filepath = data_dir / \"inflation_PEN.csv\",\n",
    "    date_col = \"date\",\n",
    "    rate_col = \"var%_12_months_inflation_value\",\n",
    "    out_name = \"inflation_PEN_daily.csv\",\n",
    "    source_unit = \"percent\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# USA (from_CPI-U_12_months_ago) -> given in percent\n",
    "# -----------------------------\n",
    "monthly_inflation_to_daily(\n",
    "    filepath = data_dir / \"inflation_USA.csv\",\n",
    "    date_col = \"date\",\n",
    "    rate_col = \"from_CPI-U_12_months_ago\",\n",
    "    out_name = \"inflation_USA_daily.csv\",\n",
    "    source_unit = \"percent\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# South Africa (value_year_on_year) -> given in percent\n",
    "# -----------------------------\n",
    "monthly_inflation_to_daily(\n",
    "    filepath = data_dir / \"inflation_ZAR.csv\",\n",
    "    date_col = \"date\",\n",
    "    rate_col = \"value_year_on_year\",\n",
    "    out_name = \"inflation_ZAR_daily.csv\",\n",
    "    source_unit = \"percent\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
